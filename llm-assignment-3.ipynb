{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:06:38.708039Z","iopub.execute_input":"2024-11-04T14:06:38.708689Z","iopub.status.idle":"2024-11-04T14:06:39.710167Z","shell.execute_reply.started":"2024-11-04T14:06:38.708651Z","shell.execute_reply":"2024-11-04T14:06:39.709354Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:06:43.550173Z","iopub.execute_input":"2024-11-04T14:06:43.551174Z","iopub.status.idle":"2024-11-04T14:07:17.755399Z","shell.execute_reply.started":"2024-11-04T14:06:43.551115Z","shell.execute_reply":"2024-11-04T14:07:17.754197Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np\nfrom huggingface_hub import interpreter_login\n\ninterpreter_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:07:21.940810Z","iopub.execute_input":"2024-11-04T14:07:21.941651Z","iopub.status.idle":"2024-11-04T14:08:18.258584Z","shell.execute_reply.started":"2024-11-04T14:07:21.941607Z","shell.execute_reply":"2024-11-04T14:08:18.257671Z"}},"outputs":[{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your token (input will not be visible):  ········\nAdd token as git credential? (Y/n)  n\n"},{"name":"stdout","text":"Token is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"ds = load_dataset(\"stanfordnlp/snli\")\ntrain_org = ds['train']\ntest_org = ds['test']\nval_org = ds['validation']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:08:22.485138Z","iopub.execute_input":"2024-11-04T14:08:22.485906Z","iopub.status.idle":"2024-11-04T14:08:26.465670Z","shell.execute_reply.started":"2024-11-04T14:08:22.485866Z","shell.execute_reply":"2024-11-04T14:08:26.464866Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/16.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68363b83a4fa4782bdc35da41c4b5d3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/412k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db6363478dc946f78c7b30f2d1cab6c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/413k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0c51e4892b8439cbd4938da8eea9235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/19.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9315024076b4f44a822ce49c00275dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eba8e4ff4084d82a716d248a76ce148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda8cf7f210740a6ad270f2ef6fb539a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15912dc8ff1445da9e465728ce52c2e"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train = train_org.select(range(0, len(train_org), 550))[:1000]\ntest = test_org.select(range(0, len(test_org), 100))[:100]\nval = val_org.select(range(0, len(val_org), 100))[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:08:40.913425Z","iopub.execute_input":"2024-11-04T14:08:40.914317Z","iopub.status.idle":"2024-11-04T14:08:40.957025Z","shell.execute_reply.started":"2024-11-04T14:08:40.914278Z","shell.execute_reply":"2024-11-04T14:08:40.956302Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(load_in_4bit=True,bnb_4bit_quant_type='nf4',bnb_4bit_compute_dtype=compute_dtype,bnb_4bit_use_double_quant=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:08:43.472191Z","iopub.execute_input":"2024-11-04T14:08:43.473100Z","iopub.status.idle":"2024-11-04T14:08:43.478892Z","shell.execute_reply.started":"2024-11-04T14:08:43.473058Z","shell.execute_reply":"2024-11-04T14:08:43.477943Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model_name='microsoft/phi-2'\ndevice_map = {\"\": 0}\noriginal_model = AutoModelForCausalLM.from_pretrained(model_name, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:29:06.825363Z","iopub.execute_input":"2024-11-04T17:29:06.825775Z","iopub.status.idle":"2024-11-04T17:29:10.440992Z","shell.execute_reply.started":"2024-11-04T17:29:06.825738Z","shell.execute_reply":"2024-11-04T17:29:10.440025Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b5962372ff14f21a4391b13efff767e"}},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:29:13.567028Z","iopub.execute_input":"2024-11-04T17:29:13.567809Z","iopub.status.idle":"2024-11-04T17:29:13.752411Z","shell.execute_reply.started":"2024-11-04T17:29:13.567769Z","shell.execute_reply":"2024-11-04T17:29:13.751568Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"%%time\nfrom transformers import set_seed\nseed = 42\nset_seed(seed)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef create_prompt(premise, hypothesis):\n    prompt = f\"\"\"Instruct: Check whether the hypothesis entails the premise or not. Follow the below format:\n    0 -> The hypothesis entails the premise\n    1 -> The premise and hypothesis neither entail nor contradict each other\n    2 -> The hypothesis contradicts the premise\n    Output only one single numerical value out of 0,1,2.\n\n    Premise: {premise}\n    Hypothesis: {hypothesis}\n    \n    Output:\n    \"\"\"\n    return prompt\ndef get_answer(output):\n    answer = None\n    try:\n        answer = int((output.split(\"Output:\\n\")[-1].strip().split(\"\\n\")[0]).split(\" \")[0])\n    except:\n        answer = \"Incorrect format\"\n    return answer\n\ndef zero_shot_inference(model, tokenizer, premise, hypothesis):\n    prompt = create_prompt(premise, hypothesis)\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(input_ids.device)\n\n    with torch.no_grad():\n        generated_ids = model.generate(input_ids, max_length=input_ids.size(1)+64)\n\n    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    answer = get_answer(output)\n    return answer\n\npretrained_labels = []\n\ncorrect_responses = 0\ntotal = len(test['premise'])\nincorrect_format = 0\nfor index in range(0, len(test['premise'])):\n    if(index%11 == 0):\n        print(index)\n\n    premise = test['premise'][index]\n    hypothesis = test['hypothesis'][index]\n    original_label = test['label'][index]\n\n    predicted_label = zero_shot_inference(original_model, tokenizer, premise, hypothesis)    \n    if(predicted_label==\"Incorrect format\"):\n        incorrect_format+=1\n    if(int(predicted_label) == original_label):\n        correct_responses+=1\n\n    pretrained_labels.append(int(predicted_label))\n\naccuracy = correct_responses*100/(total-incorrect_format)\nprint(\"Accuracy before fine-tuning: \", accuracy)\nprint(\"Samples with incorrect format: \", incorrect_format)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:29:19.949175Z","iopub.execute_input":"2024-11-04T17:29:19.949605Z","iopub.status.idle":"2024-11-04T17:35:20.885353Z","shell.execute_reply.started":"2024-11-04T17:29:19.949550Z","shell.execute_reply":"2024-11-04T17:35:20.884565Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"0\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"11\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"22\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"33\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"44\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"55\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"66\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"77\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"88\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"99\nAccuracy before fine-tuning:  54.0\nSamples with incorrect format:  0\nCPU times: user 6min, sys: 247 ms, total: 6min 1s\nWall time: 6min\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:27:57.722638Z","iopub.execute_input":"2024-11-04T15:27:57.723288Z","iopub.status.idle":"2024-11-04T15:27:57.727449Z","shell.execute_reply.started":"2024-11-04T15:27:57.723235Z","shell.execute_reply":"2024-11-04T15:27:57.726539Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"dataset_test = Dataset.from_dict(test)\ndataset_train = Dataset.from_dict(train)\ndataset_val = Dataset.from_dict(val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:28:33.871542Z","iopub.execute_input":"2024-11-04T15:28:33.872175Z","iopub.status.idle":"2024-11-04T15:28:33.899881Z","shell.execute_reply.started":"2024-11-04T15:28:33.872134Z","shell.execute_reply":"2024-11-04T15:28:33.898964Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(dataset_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:35:38.139963Z","iopub.execute_input":"2024-11-04T15:35:38.140872Z","iopub.status.idle":"2024-11-04T15:35:38.145532Z","shell.execute_reply.started":"2024-11-04T15:35:38.140831Z","shell.execute_reply":"2024-11-04T15:35:38.144552Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['premise', 'hypothesis', 'label'],\n    num_rows: 1000\n})\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def create_prompt_formats(sample):   \n    premise = sample['premise']\n    hypothesis = sample['hypothesis']\n    original_label = sample['label']\n    \n    INTRO = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n    \n    prompt = f\"\"\"### Instruct: Check whether the hypothesis entails the premise or not. Follow the below format:\n    0 -> The hypothesis entails the premise\n    1 -> The premise and hypothesis neither entail nor contradict each other\n    2 -> The hypothesis contradicts the premise\n    Output only one single numerical value out of 0,1,2.\n\n    Premise: {premise}\n    Hypothesis: {hypothesis}\n    \n    ### Output: {original_label}\n    \"\"\"\n    \n    intro = f\"\\n{INTRO}\"\n    instruction = f\"{prompt}\"\n    end = f\"### End\"\n    formatted_prompt = intro+\"\\n\\n\"+ instruction+\"\\n\\n\"+end\n    sample[\"text\"] = formatted_prompt\n    return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:39:34.380383Z","iopub.execute_input":"2024-11-04T15:39:34.381262Z","iopub.status.idle":"2024-11-04T15:39:34.387179Z","shell.execute_reply.started":"2024-11-04T15:39:34.381221Z","shell.execute_reply":"2024-11-04T15:39:34.386278Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def get_max_length(model):\n    conf = model.config\n    max_length = None\n    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n        max_length = getattr(model.config, length_setting, None)\n        if max_length:\n            print(f\"Found max lenth: {max_length}\")\n            break\n    if not max_length:\n        max_length = 1024\n        print(f\"Using default max length: {max_length}\")\n    return max_length\n\n\ndef preprocess_batch(batch, tokenizer, max_length):\n    return tokenizer(\n        batch[\"text\"],\n        max_length=max_length,\n        truncation=True,\n    )\n\ndef preprocess_dataset(tokenizer, max_length,seed, dataset):\n    \n    print(\"Preprocessing\")\n    \n    dataset = dataset.map(create_prompt_formats)\n    \n    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n    dataset = dataset.map(\n        _preprocessing_function,\n        batched=True,\n        remove_columns=['premise', 'hypothesis', 'label'],\n    )\n\n    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n    dataset = dataset.shuffle(seed=seed)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:46:36.483187Z","iopub.execute_input":"2024-11-04T15:46:36.483615Z","iopub.status.idle":"2024-11-04T15:46:36.493564Z","shell.execute_reply.started":"2024-11-04T15:46:36.483576Z","shell.execute_reply":"2024-11-04T15:46:36.492628Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def get_datasets(train,val):\n    train_dataset = preprocess_dataset(tokenizer, 2048,seed, dataset_train)\n    val_dataset = preprocess_dataset(tokenizer, 2048,seed, dataset_val)\n    return train_dataset,val_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:46:40.829206Z","iopub.execute_input":"2024-11-04T15:46:40.829948Z","iopub.status.idle":"2024-11-04T15:46:40.835000Z","shell.execute_reply.started":"2024-11-04T15:46:40.829912Z","shell.execute_reply":"2024-11-04T15:46:40.834054Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from functools import partial\n\nmax_length = get_max_length(original_model)\nprint(\"Max Length: \", max_length)\ntrain_dataset,val_dataset = get_datasets(dataset_train,dataset_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:46:44.584684Z","iopub.execute_input":"2024-11-04T15:46:44.585444Z","iopub.status.idle":"2024-11-04T15:46:51.409014Z","shell.execute_reply.started":"2024-11-04T15:46:44.585395Z","shell.execute_reply":"2024-11-04T15:46:51.408066Z"}},"outputs":[{"name":"stdout","text":"Found max lenth: 2048\nMax Length:  2048\nPreprocessing\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b55652f252f458680aa6f6f1b0b49d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df17ac4a10a48aaa1b970c55f42fb62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c47226fb460d49f790674e82f8d18e58"}},"metadata":{}},{"name":"stdout","text":"Preprocessing\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29b87cb54b5342b78bdb1f525124cb94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d99198e302a46e2807095b4c3c60e90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e69a59bf1b5a41da9c7a5bf1ff5f485b"}},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"val_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T16:04:52.039933Z","iopub.execute_input":"2024-11-04T16:04:52.040321Z","iopub.status.idle":"2024-11-04T16:04:52.046445Z","shell.execute_reply.started":"2024-11-04T16:04:52.040283Z","shell.execute_reply":"2024-11-04T16:04:52.045475Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'input_ids', 'attention_mask'],\n    num_rows: 100\n})"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nfrom peft import prepare_model_for_kbit_training\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:49:18.213470Z","iopub.execute_input":"2024-11-04T15:49:18.214363Z","iopub.status.idle":"2024-11-04T15:49:18.219069Z","shell.execute_reply.started":"2024-11-04T15:49:18.214313Z","shell.execute_reply":"2024-11-04T15:49:18.217935Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"original_model = prepare_model_for_kbit_training(original_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:49:19.880121Z","iopub.execute_input":"2024-11-04T15:49:19.880545Z","iopub.status.idle":"2024-11-04T15:49:19.899768Z","shell.execute_reply.started":"2024-11-04T15:49:19.880494Z","shell.execute_reply":"2024-11-04T15:49:19.898975Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"config = LoraConfig(\n    r=32, #Rank\n    lora_alpha=32,\n    target_modules=[\n        'q_proj',\n        'k_proj',\n        'v_proj',\n        'dense'\n    ],\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    task_type=\"CAUSAL_LM\",\n)\n\n# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\noriginal_model.gradient_checkpointing_enable()\n\npeft_model = get_peft_model(original_model, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:49:32.480061Z","iopub.execute_input":"2024-11-04T15:49:32.480897Z","iopub.status.idle":"2024-11-04T15:49:32.950327Z","shell.execute_reply.started":"2024-11-04T15:49:32.480855Z","shell.execute_reply":"2024-11-04T15:49:32.949452Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n\n    trainable_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n    total_params = sum(param.numel() for param in model.parameters())\n    trainable_percentage = (trainable_params / total_params) * 100 if total_params > 0 else 0\n    print(f\"Trainable Parameters: {trainable_params}\")\n    print(f\"Total Parameters: {total_params}\")\n    print(f\"Percentage of Trainable Parameters: {trainable_percentage:.2f}%\")\n    return trainable_params\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:53:50.607161Z","iopub.execute_input":"2024-11-04T15:53:50.607912Z","iopub.status.idle":"2024-11-04T15:53:50.614054Z","shell.execute_reply.started":"2024-11-04T15:53:50.607871Z","shell.execute_reply":"2024-11-04T15:53:50.612980Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(peft_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T15:53:53.065091Z","iopub.execute_input":"2024-11-04T15:53:53.065788Z","iopub.status.idle":"2024-11-04T15:53:53.084261Z","shell.execute_reply.started":"2024-11-04T15:53:53.065748Z","shell.execute_reply":"2024-11-04T15:53:53.083353Z"}},"outputs":[{"name":"stdout","text":"Trainable Parameters: 20971520\nTotal Parameters: 1542364160\nPercentage of Trainable Parameters: 1.36%\n20971520\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import time\nimport torch\nfrom transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n\noutput_dir = f'./checkpoints'\n\npeft_training_args = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=5,\n    warmup_steps=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=2,\n    learning_rate=5e-4,\n    optim=\"adamw_8bit\",\n    logging_steps=100,\n    logging_dir=\"./logs\",\n    save_strategy=\"epoch\",\n    evaluation_strategy=\"epoch\",\n    do_eval=True,\n    gradient_checkpointing=False,\n    report_to=\"none\",\n    overwrite_output_dir=False,\n    group_by_length=True,\n)\n\npeft_model.config.use_cache = False\n\npeft_trainer = Trainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    args=peft_training_args,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n\nstart_time = time.time()  # Start time\n\nif torch.cuda.is_available():\n    torch.cuda.reset_peak_memory_stats()\n    torch.cuda.synchronize()  # Synchronize before starting training\n\n# Training\npeft_trainer.train()\n\nend_time = time.time()\ntraining_time = end_time - start_time\n\nif torch.cuda.is_available():\n    peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)  # Convert to GB\n    print(f\"Peak Memory Usage (GB): {peak_memory:.2f}\")\nelse:\n    peak_memory = None\n    print(\"CUDA not available; unable to track peak memory usage.\")\n\nprint(f\"Time taken to fine-tune the model (seconds): {training_time:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T16:05:10.296273Z","iopub.execute_input":"2024-11-04T16:05:10.297116Z","iopub.status.idle":"2024-11-04T16:43:01.238228Z","shell.execute_reply.started":"2024-11-04T16:05:10.297078Z","shell.execute_reply":"2024-11-04T16:43:01.237305Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [625/625 37:45, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.598300</td>\n      <td>0.492091</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.457100</td>\n      <td>0.481063</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.429400</td>\n      <td>0.478328</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.392600</td>\n      <td>0.482428</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.381200</td>\n      <td>0.491142</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"},{"name":"stdout","text":"Peak Memory Usage (GB): 3.24\nTime taken to fine-tune the model (seconds): 2270.90\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nbase_model_id = \"microsoft/phi-2\"\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_id, \n                                                      device_map='auto',\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)\neval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\neval_tokenizer.pad_token = eval_tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T16:51:50.804019Z","iopub.execute_input":"2024-11-04T16:51:50.804472Z","iopub.status.idle":"2024-11-04T16:51:54.901528Z","shell.execute_reply.started":"2024-11-04T16:51:50.804424Z","shell.execute_reply":"2024-11-04T16:51:54.900545Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3750f6683d34dc283d12cb725412fc8"}},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"import os\n\nlst = os.listdir(\"/kaggle/working/checkpoints\")\n\nfor file in lst:\n    print(f\"/kaggle/working/checkpoints/{file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T16:56:53.363088Z","iopub.execute_input":"2024-11-04T16:56:53.363836Z","iopub.status.idle":"2024-11-04T16:56:53.369667Z","shell.execute_reply.started":"2024-11-04T16:56:53.363791Z","shell.execute_reply":"2024-11-04T16:56:53.368588Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/checkpoints/checkpoint-250\n/kaggle/working/checkpoints/checkpoint-625\n/kaggle/working/checkpoints/checkpoint-125\n/kaggle/working/checkpoints/checkpoint-500\n/kaggle/working/checkpoints/checkpoint-375\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"from peft import PeftModel\n\nft_model = PeftModel.from_pretrained(base_model, \"/kaggle/working/checkpoints/checkpoint-625\",torch_dtype=torch.float16,is_trainable=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T16:57:50.513237Z","iopub.execute_input":"2024-11-04T16:57:50.513664Z","iopub.status.idle":"2024-11-04T16:57:51.136233Z","shell.execute_reply.started":"2024-11-04T16:57:50.513627Z","shell.execute_reply":"2024-11-04T16:57:51.135353Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"correct_responses = 0\ntotal = len(test['premise'])\nincorrect_format = 0\n\nfinetuned_labels = []\n\nfor index in range(0, len(test['premise'])):\n    if(index%11 == 0):\n        print(index)\n\n    premise = test['premise'][index]\n    hypothesis = test['hypothesis'][index]\n    original_label = test['label'][index]\n\n    predicted_label = zero_shot_inference(ft_model, tokenizer, premise, hypothesis)    \n    if(predicted_label==\"Incorrect format\"):\n        incorrect_format+=1\n    if(int(predicted_label) == original_label):\n        correct_responses+=1\n\n    finetuned_labels.append(int(predicted_label))\n\naccuracy = correct_responses*100/(total-incorrect_format)\nprint(\"Accuracy after fine-tuning: \", accuracy)\nprint(\"Samples with incorrect format: \", incorrect_format)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:36:27.681163Z","iopub.execute_input":"2024-11-04T17:36:27.682138Z","iopub.status.idle":"2024-11-04T17:41:26.763333Z","shell.execute_reply.started":"2024-11-04T17:36:27.682089Z","shell.execute_reply":"2024-11-04T17:41:26.762318Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"0\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"11\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"22\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"33\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"44\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"55\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"66\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"77\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"88\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"99\nAccuracy after fine-tuning:  87.0\nSamples with incorrect format:  0\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"### Downloading the Model Checkpoints\n!zip -r file.zip /kaggle/working/checkpoints\n\n!ls\n\nfrom IPython.display import FileLink\nFileLink(r'file.zip')\n\nimport zipfile\nimport os\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n                \n    file_size = os.path.getsize(file_name)\n    readable_size = file_size / (1024 ** 2)  # Convert to MB\n    print(f\"Created zip file '{file_name}' with size: {readable_size:.2f} MB\")\n\n    return FileLink(file_name)\nzip_dir()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:09:16.073700Z","iopub.execute_input":"2024-11-04T17:09:16.074250Z","iopub.status.idle":"2024-11-04T17:09:54.978778Z","shell.execute_reply.started":"2024-11-04T17:09:16.074209Z","shell.execute_reply":"2024-11-04T17:09:54.977394Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/checkpoints/ (stored 0%)\n  adding: kaggle/working/checkpoints/checkpoint-250/ (stored 0%)\n  adding: kaggle/working/checkpoints/checkpoint-250/scheduler.pt (deflated 56%)\n  adding: kaggle/working/checkpoints/checkpoint-250/optimizer.pt (deflated 10%)\n  adding: kaggle/working/checkpoints/checkpoint-250/rng_state.pth (deflated 25%)\n  adding: kaggle/working/checkpoints/checkpoint-250/README.md (deflated 66%)\n  adding: kaggle/working/checkpoints/checkpoint-250/adapter_config.json (deflated 53%)\n  adding: kaggle/working/checkpoints/checkpoint-250/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/checkpoints/checkpoint-250/trainer_state.json (deflated 62%)\n  adding: kaggle/working/checkpoints/checkpoint-250/training_args.bin (deflated 52%)\n  adding: kaggle/working/checkpoints/checkpoint-625/ (stored 0%)\n  adding: kaggle/working/checkpoints/checkpoint-625/scheduler.pt (deflated 56%)\n  adding: kaggle/working/checkpoints/checkpoint-625/optimizer.pt (deflated 10%)\n  adding: kaggle/working/checkpoints/checkpoint-625/rng_state.pth (deflated 25%)\n  adding: kaggle/working/checkpoints/checkpoint-625/README.md (deflated 66%)\n  adding: kaggle/working/checkpoints/checkpoint-625/adapter_config.json (deflated 53%)\n  adding: kaggle/working/checkpoints/checkpoint-625/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/checkpoints/checkpoint-625/trainer_state.json (deflated 71%)\n  adding: kaggle/working/checkpoints/checkpoint-625/training_args.bin (deflated 52%)\n  adding: kaggle/working/checkpoints/checkpoint-125/ (stored 0%)\n  adding: kaggle/working/checkpoints/checkpoint-125/scheduler.pt (deflated 56%)\n  adding: kaggle/working/checkpoints/checkpoint-125/optimizer.pt (deflated 10%)\n  adding: kaggle/working/checkpoints/checkpoint-125/rng_state.pth (deflated 25%)\n  adding: kaggle/working/checkpoints/checkpoint-125/README.md (deflated 66%)\n  adding: kaggle/working/checkpoints/checkpoint-125/adapter_config.json (deflated 53%)\n  adding: kaggle/working/checkpoints/checkpoint-125/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/checkpoints/checkpoint-125/trainer_state.json (deflated 56%)\n  adding: kaggle/working/checkpoints/checkpoint-125/training_args.bin (deflated 52%)\n  adding: kaggle/working/checkpoints/checkpoint-500/ (stored 0%)\n  adding: kaggle/working/checkpoints/checkpoint-500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/checkpoints/checkpoint-500/optimizer.pt (deflated 10%)\n  adding: kaggle/working/checkpoints/checkpoint-500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/checkpoints/checkpoint-500/README.md (deflated 66%)\n  adding: kaggle/working/checkpoints/checkpoint-500/adapter_config.json (deflated 53%)\n  adding: kaggle/working/checkpoints/checkpoint-500/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/checkpoints/checkpoint-500/trainer_state.json (deflated 69%)\n  adding: kaggle/working/checkpoints/checkpoint-500/training_args.bin (deflated 52%)\n  adding: kaggle/working/checkpoints/checkpoint-375/ (stored 0%)\n  adding: kaggle/working/checkpoints/checkpoint-375/scheduler.pt (deflated 55%)\n  adding: kaggle/working/checkpoints/checkpoint-375/optimizer.pt (deflated 10%)\n  adding: kaggle/working/checkpoints/checkpoint-375/rng_state.pth (deflated 25%)\n  adding: kaggle/working/checkpoints/checkpoint-375/README.md (deflated 66%)\n  adding: kaggle/working/checkpoints/checkpoint-375/adapter_config.json (deflated 53%)\n  adding: kaggle/working/checkpoints/checkpoint-375/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/checkpoints/checkpoint-375/trainer_state.json (deflated 66%)\n  adding: kaggle/working/checkpoints/checkpoint-375/training_args.bin (deflated 52%)\ncheckpoints  directory.zip  file.zip\nCreated zip file 'directory.zip' with size: 1158.67 MB\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/directory.zip","text/html":"<a href='directory.zip' target='_blank'>directory.zip</a><br>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"### Comparison\n\n### Printing 5 cases where pretrained labels were incorrect and finetuned labels were correct\ncount=0\nct=0\nfor i in range(len(test['label'])):\n    original_label = test['label'][i]\n    pretrained_label = pretrained_labels[i]\n    finetuned_label = finetuned_labels[i]\n\n    if(pretrained_label != original_label and finetuned_label == original_label):\n        if(ct<5):\n            print(\"-----------\"+str(ct+1)+\"-----------\")\n            print(\"Premise: \", test['premise'][i])\n            print(\"Hypothesis: \", test['hypothesis'][i])\n            print(\"Label: \", test['label'][i])\n            print(\"Pretrained Label: \", pretrained_labels[i])\n            print(\"Finetuned Label: \", finetuned_labels[i])\n        ct+=1\n        count+=1\n\nprint(\"Number of cases that were corrected by the fine-tuned model:\",count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:59:28.471719Z","iopub.execute_input":"2024-11-04T17:59:28.472547Z","iopub.status.idle":"2024-11-04T17:59:28.480778Z","shell.execute_reply.started":"2024-11-04T17:59:28.472505Z","shell.execute_reply":"2024-11-04T17:59:28.479863Z"}},"outputs":[{"name":"stdout","text":"-----------1-----------\nPremise:  a woman in a black shirt looking at a bicycle.\nHypothesis:  A woman dressed in black shops for a bicycle.\nLabel:  1\nPretrained Label:  0\nFinetuned Label:  1\n-----------2-----------\nPremise:  A group of people stand near and on a large black square on the ground with some yellow writing on it.\nHypothesis:  a group of people wait\nLabel:  1\nPretrained Label:  0\nFinetuned Label:  1\n-----------3-----------\nPremise:  Two men in neon yellow shirts busily sawing a log in half.\nHypothesis:  Two men are cutting wood to build a table.\nLabel:  1\nPretrained Label:  0\nFinetuned Label:  1\n-----------4-----------\nPremise:  A man is renovating a room.\nHypothesis:  A man is using a hammer in a room.\nLabel:  1\nPretrained Label:  0\nFinetuned Label:  1\n-----------5-----------\nPremise:  An Ambulance is passing a man wearing a bandanna and girl.\nHypothesis:  The man in the bandana is running after the ambulance\nLabel:  2\nPretrained Label:  1\nFinetuned Label:  2\nNumber of cases that were corrected by the fine-tuned model: 34\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"### Printing 5 cases where pretrained labels were incorrect and finetuned labels were also incorrect\ncount=0\nct=0\nfor i in range(len(test['label'])):\n    original_label = test['label'][i]\n    pretrained_label = pretrained_labels[i]\n    finetuned_label = finetuned_labels[i]\n\n    if(pretrained_label != original_label and finetuned_label != original_label):\n        if(ct<5):\n            print(\"-----------\"+str(ct+1)+\"-----------\")\n            print(\"Premise: \", test['premise'][i])\n            print(\"Hypothesis: \", test['hypothesis'][i])\n            print(\"Label: \", test['label'][i])\n            print(\"Pretrained Label: \", pretrained_labels[i])\n            print(\"Finetuned Label: \", finetuned_labels[i])\n        ct+=1\n        count+=1\n\nprint(\"Number of cases that were not corrected by the fine-tuned model:\",count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:00:15.990772Z","iopub.execute_input":"2024-11-04T18:00:15.991211Z","iopub.status.idle":"2024-11-04T18:00:16.000621Z","shell.execute_reply.started":"2024-11-04T18:00:15.991173Z","shell.execute_reply":"2024-11-04T18:00:15.999658Z"}},"outputs":[{"name":"stdout","text":"-----------1-----------\nPremise:  This church choir sings to the masses as they sing joyous songs from the book at a church.\nHypothesis:  The church has cracks in the ceiling.\nLabel:  1\nPretrained Label:  2\nFinetuned Label:  2\n-----------2-----------\nPremise:  Two men climbing on a wooden scaffold.\nHypothesis:  Two sad men climbing on a wooden scaffold.\nLabel:  1\nPretrained Label:  2\nFinetuned Label:  2\n-----------3-----------\nPremise:  A woman is standing near three stores, two have beautiful artwork and the other store has Largo written on it.\nHypothesis:  A woman standing on a street corner outside beside three different stores, two of which contain beautiful artwork and one with a Largo sign.\nLabel:  0\nPretrained Label:  1\nFinetuned Label:  1\n-----------4-----------\nPremise:  Military personnel are shopping\nHypothesis:  Military personnel are in the mall.\nLabel:  1\nPretrained Label:  0\nFinetuned Label:  0\n-----------5-----------\nPremise:  An older gentleman wearing a hat is walking on crutches next to a busy street.\nHypothesis:  A man with a walking stick is next to the street.\nLabel:  2\nPretrained Label:  1\nFinetuned Label:  1\nNumber of cases that were not corrected by the fine-tuned model: 12\n","output_type":"stream"}],"execution_count":75}]}